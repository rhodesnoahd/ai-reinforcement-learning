{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "844c5a67",
   "metadata": {},
   "source": [
    "# <center>ANALYSIS OF PERFORMANCE VARIABLES</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11981103",
   "metadata": {},
   "source": [
    "<h3>Reading all CSV files related to the experiments</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295dc31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5222c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rewards(vdf, tdf):\n",
    "     \"\"\"\n",
    "    This function reads the two csv files which contains data about \n",
    "    the performance variables (rewards, Manhattan distance, terminal state steps )\n",
    "    \"\"\"\n",
    "    vdf['Male Rewards'] = vdf['Rewards']\n",
    "    vdf['Female Rewards'] = vdf['Rewards']\n",
    "    m_total = 0\n",
    "    f_total = 0\n",
    "    j = 0\n",
    "    terminal_points = tdf.cumsum()\n",
    "    for i in range(vdf.shape[0]):\n",
    "        if vdf['Agent'][i] == 'F':\n",
    "            f_total += vdf['Rewards'][i]\n",
    "        else:\n",
    "            m_total += vdf['Rewards'][i]\n",
    "        vdf.loc[i, 'Male Rewards'] = m_total\n",
    "        vdf.loc[i, 'Female Rewards'] = f_total\n",
    "        if j < terminal_points.shape[0] and i + 1 == terminal_points.loc[j][0]:\n",
    "            m_total = 0\n",
    "            f_total = 0\n",
    "            j += 1\n",
    "    vdf['Total Rewards'] = vdf['Male Rewards'] + vdf['Female Rewards']\n",
    "#Initializing\n",
    "cols = ['n', 'Rewards', 'Distance', 'Agent']\n",
    "var_data = [pd.read_csv(filepath_or_buffer='viz/visualization.csv', header=None)]\n",
    "terminal_state_data = [pd.read_csv(filepath_or_buffer='viz/terminal_states.csv')]\n",
    "var_data[0].columns = cols\n",
    "get_rewards(var_data[-1], terminal_state_data[-1])\n",
    "# Loop\n",
    "for i in range(1,42):\n",
    "    var_data.append(pd.read_csv(filepath_or_buffer=f'viz/visualization{i}.csv', header=None))\n",
    "    var_data[-1].columns = cols\n",
    "    terminal_state_data.append(pd.read_csv(filepath_or_buffer=f'viz/terminal_states{i}.csv'))\n",
    "    get_rewards(var_data[-1], terminal_state_data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462dfe93",
   "metadata": {},
   "source": [
    "<h3> Processing commands to look up different datasets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be802d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index(rl, exp, seed):\n",
    "    \"\"\"\n",
    "    Get index of experiment results\n",
    "    \"\"\"\n",
    "    rl = ['ss', 'vs', 'ms'].index(rl)\n",
    "    exp = ['1a', '1b', '1c', '2', '3a', '3b', '4'].index(exp)\n",
    "    seed = [1, 42].index(seed)\n",
    "    return 14*rl+2*exp+seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6111b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(rl, exp, seed):\n",
    "    \"\"\"\n",
    "    Return experiment data\n",
    "    \"\"\"\n",
    "    return var_data[index(rl, exp, seed)]\n",
    "def terminals(rl, exp, seed):\n",
    "    \"\"\"\n",
    "    Return terminal state data\n",
    "    \"\"\"\n",
    "    return terminal_state_data[index(rl, exp, seed)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c2f8e",
   "metadata": {},
   "source": [
    "<h3>Auxilliary plotting functions for visualization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e576cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_plot_compare_rl(exp, seed):\n",
    "    \"\"\"\n",
    "    This function compares the three RL models for the given experiment and seed\n",
    "    \"\"\"\n",
    "    df1 = data('ms',exp,seed)\n",
    "    df2 = data('vs',exp,seed)\n",
    "    df3 = data('ss',exp,seed)\n",
    "    df = df1.join(df2, on='n', how='outer', lsuffix=' ms', rsuffix=' vs')\n",
    "    df = df.join(df3, on='n', how='outer', rsuffix=' ss')\n",
    "    df = df1.merge(df2, on='n', how='outer', suffixes=(' ms', ' vs'))\n",
    "    df = df.merge(df3, on='n', how='outer', suffixes=(None, ' ss'))\n",
    "    assert(df.shape[0] == max(df1.shape[0], df2.shape[0], df3.shape[0]))\n",
    "    df['Male Rewards ss'] = df['Male Rewards']\n",
    "    df['Female Rewards ss'] = df['Female Rewards']\n",
    "    fig = px.line(df, x='n', y=['Male Rewards ms', 'Female Rewards ms',\n",
    "                               'Male Rewards vs', 'Female Rewards vs',\n",
    "                               'Male Rewards ss', 'Female Rewards ss'])\n",
    "    fig.update_xaxes(title_text='Number of steps')\n",
    "    fig.update_yaxes(title_text='Agent reward')\n",
    "    fig.update_layout(title_text=f'Comparison of agent rewards for all RL spaces for experiment {exp} and seed {seed}')\n",
    "    fig.show()\n",
    "    pio.write_image(fig, f'rpcr_{exp}_{seed}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec751711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_state_compare_rl(exp, seed):\n",
    "    \"\"\"\n",
    "    This function compares the terminal state steps for the three RL states for the given experiment and seed\n",
    "    \"\"\"\n",
    "    df1 = terminals('ms',exp,seed)\n",
    "    df1['i'] = df1.index\n",
    "    df2 = terminals('vs',exp,seed)\n",
    "    df2['i'] = df2.index\n",
    "    df3 = terminals('ss',exp,seed)\n",
    "    df3['i'] = df3.index\n",
    "    df = df1.merge(df2, on='i', how='outer', suffixes=(' ms', ' vs'))\n",
    "    df = df.merge(df3, on='i', how='outer', suffixes=(None, ' ss'))\n",
    "    assert(df.shape[0] == max(df1.shape[0], df2.shape[0], df3.shape[0]))\n",
    "    df['Steps ss'] = df['Steps']\n",
    "    fig1 = px.bar(df, y=['Steps ms', 'Steps ss', 'Steps vs'], orientation = \"v\", barmode = 'group')    \n",
    "    fig1.update_xaxes(title_text='Terminal State')\n",
    "    fig1.update_yaxes(title_text='Steps to reach state')\n",
    "    fig1.update_layout(title_text=f'Comparison of terminal state steps for all RL spaces for experiment {exp} and seed {seed}')\n",
    "    fig1.show()\n",
    "    pio.write_image(fig1, f'tscr_{exp}_{seed}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1090742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_state_compare_exp3(rl, seed):\n",
    "    \"\"\"\n",
    "    This function compares the terminal state steps for the Experiment 3 ones\n",
    "    \"\"\"\n",
    "    df1 = terminals(rl,'1c',seed)\n",
    "    df1['i'] = df1.index\n",
    "    df2 = terminals(rl,'3a',seed)\n",
    "    df2['i'] = df2.index\n",
    "    df3 = terminals(rl,'3b',seed)\n",
    "    df3['i'] = df3.index\n",
    "    df = df1.merge(df2, on='i', how='outer', suffixes=(' 1c', ' 3a'))\n",
    "    df = df.merge(df3, on='i', how='outer', suffixes=(None, ' 3b'))\n",
    "    assert(df.shape[0] == max(df1.shape[0], df2.shape[0], df3.shape[0]))\n",
    "    df['Steps 3b'] = df['Steps']\n",
    "    fig1 = px.bar(df, y=['Steps 1c', 'Steps 3a', 'Steps 3b'], orientation = \"v\", barmode = 'group')\n",
    "    fig1.update_xaxes(title_text='Terminal State')\n",
    "    fig1.update_yaxes(title_text='Steps to reach state')\n",
    "    fig1.update_layout(title_text=f'Comparison of terminal state steps for experiment 3 versions and seed {seed} using {rl} space')\n",
    "    fig1.show()\n",
    "    pio.write_image(fig1, f'tsc3_{rl}_{seed}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb07f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_state_compare_exp2(rl, seed):\n",
    "    \"\"\"\n",
    "    This function compares the terminal state steps for the Experiment 3 ones\n",
    "    \"\"\"\n",
    "    df1 = terminals(rl,'1c',seed)\n",
    "    df1['i'] = df1.index\n",
    "    df2 = terminals(rl,'2',seed)\n",
    "    df2['i'] = df2.index\n",
    "    df = df1.merge(df2, on='i', how='outer', suffixes=(' 1c', ' 2'))\n",
    "    fig1 = px.bar(df, y=['Steps 1c', 'Steps 2'], orientation = \"v\", barmode = 'group')\n",
    "    fig1.update_xaxes(title_text='Terminal State')\n",
    "    fig1.update_yaxes(title_text='Steps to reach state')\n",
    "    fig1.update_layout(title_text=f'Comparison of terminal state steps for experiment 2 versions and seed {seed} using {rl} space')\n",
    "    fig1.show()\n",
    "    pio.write_image(fig1, f'tsc2_{rl}_{seed}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8117fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_compare_total_exp1(rl, seed):\n",
    "    \"\"\"\n",
    "    This function is for comparing the three parts of Experiment 1 for the given RL model and seed\n",
    "    How does the policy affect the performance of the agent?\n",
    "    This version looks at the total reward (it is less busy)\n",
    "    \"\"\"\n",
    "    df1 = data(rl,'1a',seed)\n",
    "    df2 = data(rl,'1b',seed)\n",
    "    df3 = data(rl,'1c',seed)\n",
    "    df = df1.merge(df2, on='n', how='outer', suffixes=(' 1a', ' 1b'))\n",
    "    df = df.merge(df3, on='n', how='outer', suffixes=(None, ' 1c'))\n",
    "    assert(df.shape[0] == max(df1.shape[0], df2.shape[0], df3.shape[0]))\n",
    "    df['Total Rewards 1c'] = df['Total Rewards']\n",
    "    fig = px.line(df, x='n', y=['Total Rewards 1a', 'Total Rewards 1b', 'Total Rewards 1c'])\n",
    "    fig.update_xaxes(title_text='Number of steps')\n",
    "    fig.update_yaxes(title_text='Agent reward')\n",
    "    fig.update_layout(title_text=f'Comparison of total reward for experiment 1 versions and seed {seed} using {rl} space')\n",
    "    fig.show()\n",
    "    pio.write_image(fig, f'rct1_{rl}_{seed}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ec7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_compare_exp1(rl, seed):\n",
    "    \"\"\"\n",
    "    This function is for comparing the three parts of Experiment 1 for the given RL model and seed\n",
    "    How does the policy affect the performance of the agent?\n",
    "    \"\"\"\n",
    "    df1 = data(rl,'1a',seed)\n",
    "    df2 = data(rl,'1b',seed)\n",
    "    df3 = data(rl,'1c',seed)\n",
    "    df = df1.merge(df2, on='n', how='outer', suffixes=(' 1a', ' 1b'))\n",
    "    df = df.merge(df3, on='n', how='outer', suffixes=(None, ' 1c'))\n",
    "    assert(df.shape[0] == max(df1.shape[0], df2.shape[0], df3.shape[0]))\n",
    "    df['Male Rewards 1c'] = df['Male Rewards']\n",
    "    df['Female Rewards 1c'] = df['Female Rewards']\n",
    "    fig = px.line(df, x='n', y=['Male Rewards 1a', 'Female Rewards 1a',\n",
    "                               'Male Rewards 1b', 'Female Rewards 1b',\n",
    "                               'Male Rewards 1c', 'Female Rewards 1c'])\n",
    "    fig.update_xaxes(title_text='Number of steps')\n",
    "    fig.update_yaxes(title_text='Agent reward')\n",
    "    fig.update_layout(title_text=f'Comparison of agent rewards for experiment 1 versions and seed {seed} using {rl} space')\n",
    "    fig.show()\n",
    "    pio.write_image(fig, f'rc1_{rl}_{seed}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "212e8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_compare_total_exp3(rl, seed):\n",
    "    \"\"\"\n",
    "    This function is for comparing the three parts of Experiment 3 for the given RL model and seed\n",
    "    How does the policy affect the performance of the agent?\n",
    "    This version looks at the total reward (it is less busy)\n",
    "    \"\"\"\n",
    "    df1 = data(rl,'1c',seed)\n",
    "    df2 = data(rl,'3a',seed)\n",
    "    df3 = data(rl,'3b',seed)\n",
    "    df = df1.merge(df2, on='n', how='outer', suffixes=(' 1c', ' 3a'))\n",
    "    df = df.merge(df3, on='n', how='outer', suffixes=(None, ' 3b'))\n",
    "    assert(df.shape[0] == max(df1.shape[0], df2.shape[0], df3.shape[0]))\n",
    "    df['Total Rewards 3b'] = df['Total Rewards']\n",
    "    fig = px.line(df, x='n', y=['Total Rewards 1c', 'Total Rewards 3a', 'Total Rewards 3b'])\n",
    "    fig.update_xaxes(title_text='Number of steps')\n",
    "    fig.update_yaxes(title_text='Agent reward')\n",
    "    fig.update_layout(title_text=f'Comparison of total reward for experiment 3 versions and seed {seed} using {rl} space')\n",
    "    fig.show()\n",
    "    pio.write_image(fig, f'rct3_{rl}_{seed}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1913d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_compare_total_exp2(rl, seed):\n",
    "    \"\"\"\n",
    "    This function is for comparing Exp 2 and Exp 1.c for the given RL model and seed\n",
    "    How does the learning method affect the performance of the agent?\n",
    "    This version looks at the total reward (it is less busy)\n",
    "    \"\"\"\n",
    "    df1 = data(rl,'1c',seed)\n",
    "    df2 = data(rl,'2',seed)\n",
    "    df = df1.merge(df2, on='n', how='outer', suffixes=(' 1c', ' 2'))\n",
    "    assert(df.shape[0] == max(df1.shape[0], df2.shape[0]))\n",
    "    fig = px.line(df, x='n', y=['Total Rewards 1c', 'Total Rewards 2'])\n",
    "    fig.update_xaxes(title_text='Number of steps')\n",
    "    fig.update_yaxes(title_text='Agent reward')\n",
    "    fig.update_layout(title_text=f'Comparison of total reward for experiment 2 versions and seed {seed} using {rl} space')\n",
    "    fig.show()\n",
    "    pio.write_image(fig, f'rct2_{rl}_{seed}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95cfb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_compare_exp(exp, seed):\n",
    "    \"\"\"\n",
    "    This function is for comparing the Manhattan distances of the agents for the given experiment/seed\n",
    "    This is most important for determining bad behavior of VS\n",
    "    \"\"\"\n",
    "    df1 = data('ms',exp,seed)\n",
    "    df2 = data('vs',exp,seed)\n",
    "    df3 = data('ss',exp,seed)\n",
    "    df = df1.merge(df2, on='n', how='outer', suffixes=(' ms', ' vs'))\n",
    "    df = df.merge(df3, on='n', how='outer', suffixes=(None, ' ss'))\n",
    "    assert(df.shape[0] == max(df1.shape[0], df2.shape[0], df3.shape[0]))\n",
    "    df['Distance ss'] = df['Distance']\n",
    "    fig = px.histogram(df, x=['Distance ms', 'Distance ss', 'Distance vs'], barmode='group')\n",
    "    fig.update_xaxes(title_text='Manhattan Distance')\n",
    "    fig.update_yaxes(title_text='Frequency')\n",
    "    fig.update_layout(title_text=f'Comparison of agent L1 distances for experiment {exp} and seed {seed}')\n",
    "    fig.show()\n",
    "    pio.write_image(fig, f'dc_{exp}_{seed}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f01b82a",
   "metadata": {},
   "source": [
    "We called the auxiliary plotting functions to generate the Plotly graphs for the analysis of the performance variables for the experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
